<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>DnB Radio Stream</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" />
  <style>
    body { background: #000000; color: #eee; font-family: Arial, sans-serif; margin: 0; min-height: 100vh; overflow: hidden; display: flex; flex-direction: column; align-items: center; justify-content: center; }
    #eq-bg { position: fixed; top: 0; left: 0; width: 100vw; height: 100vh; z-index: 0; pointer-events: none; }
    .player { z-index: 2; background: #00000000; border-radius: 18px; padding: 24px 18px; box-shadow: 0 4px 32px #000a; display: flex; flex-direction: column; align-items: center; }
    /* removed play button and status styles - interactions are via keyboard and screen (pointer) */
    /* Live indicator (bottom center) */
    #live-indicator { position: fixed; bottom: 12px; left: 50%; transform: translateX(-50%); z-index: 4; display: flex; gap: 8px; align-items: center; background: rgba(0,0,0,0.5); padding: 6px 10px; border-radius: 20px; color: #fff; font-weight: 700; font-size: 12px; pointer-events: none; opacity: 0.98; }
    #live-indicator .dot { width: 10px; height: 10px; border-radius: 50%; background: #7a7a7a; box-shadow: 0 0 6px rgba(0,0,0,0.6); transition: background .2s, transform .15s, box-shadow .2s; }
    #live-indicator.live .dot { background: #ff3b30; box-shadow: 0 0 10px #ff3b30; animation: live-pulse 1000ms infinite; transform: scale(1.05); }
    @keyframes live-pulse { 0% { transform: scale(1); opacity: 1 } 50% { transform: scale(1.4); opacity: 0.75 } 100% { transform: scale(1); opacity: 1 } }
  </style>
</head>
<body>
  <canvas id="eq-bg"></canvas>
  <div id="live-indicator" aria-hidden="true">
    <span class="dot" aria-hidden="true"></span>
    <span class="label">LIVE</span>
  </div>
  <div class="player" id="playerContainer" aria-hidden="true">
    <audio id="audio" src="https://azura.drmnbss.org/listen/dnbradio/radio.mp3" crossorigin="anonymous"></audio>
  </div>
  <script type="module">
    import * as THREE from 'https://esm.sh/three@0.160.0';

    const audio = document.getElementById('audio');
    const canvas = document.getElementById('eq-bg');
    const playerContainer = document.getElementById('playerContainer');

    let audioCtx, analyser, source;
    let isPlaying = false;
    let fftSize = 128;

    const liveIndicator = document.getElementById('live-indicator');
    function updateLiveIndicator() {
      if (!liveIndicator) return;
      if (isPlaying) {
        liveIndicator.classList.add('live');
        liveIndicator.setAttribute('aria-hidden', 'false');
      } else {
        liveIndicator.classList.remove('live');
        liveIndicator.setAttribute('aria-hidden', 'true');
      }
    }

    // Three.js setup
    const scene = new THREE.Scene();
    const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
    const renderer = new THREE.WebGLRenderer({ canvas, antialias: true });
    renderer.setSize(window.innerWidth, window.innerHeight);

    // Create blob mesh
    const geometry = new THREE.IcosahedronGeometry(1, 4);
    const material = new THREE.MeshPhongMaterial({
      color: 0x00ff00,
      shininess: 100,
      wireframe: true,
      emissive: 0x00ff00,
      emissiveIntensity: 0.5
    });
    const blob = new THREE.Mesh(geometry, material);
    scene.add(blob);

    // Add lights
    const light = new THREE.PointLight(0xffffff, 1);
    light.position.set(2, 2, 2);
    scene.add(light);
    scene.add(new THREE.AmbientLight(0x222222));

    // Store original vertices
    const originalVertices = geometry.attributes.position.array.slice();
    camera.position.z = 2.5;

    function resizeCanvas() {
      const { innerWidth: w, innerHeight: h } = window;
      renderer.setSize(w, h);
      camera.aspect = w / h;
      camera.updateProjectionMatrix();
    }
    window.addEventListener('resize', resizeCanvas);

    async function ensureAudioGraph() {
      if (!audioCtx) audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      if (!analyser || !source) {
        analyser = audioCtx.createAnalyser();
        analyser.fftSize = fftSize;
        source = audioCtx.createMediaElementSource(audio);
        source.connect(analyser);
        analyser.connect(audioCtx.destination);
      }
      // resume audio context on user gesture if needed
      if (audioCtx.state === 'suspended') {
        try { await audioCtx.resume(); } catch (e) { /* ignore */ }
      }
    }

    async function togglePlayback() {
      if (!isPlaying) {
        await ensureAudioGraph();
        try {
          await audio.play();
        } catch (e) {
          // play() may fail if the user gesture didn't occur; gesture should be from key or pointer
          console.error('Playback failed:', e);
          return;
        }
        isPlaying = true;
        updateLiveIndicator();
        drawEq();
      } else {
        audio.pause();
        isPlaying = false;
        updateLiveIndicator();
      }
    }

    // Keep indicator in sync with media events (covers external changes)
    audio.addEventListener('play', () => {
      isPlaying = true;
      updateLiveIndicator();
      drawEq();
    });
    audio.addEventListener('pause', () => {
      isPlaying = false;
      updateLiveIndicator();
    });

    // Toggle on space key press
    window.addEventListener('keydown', async (e) => {
      if (e.code === 'Space') {
        await togglePlayback();
      }
    });

    // Toggle on screen pointer (mouse/touch) press anywhere
    // Use pointerdown to cover mouse, touch and pen.
    window.addEventListener('pointerdown', async (e) => {
      // ignore non-primary mouse buttons
      if (e.pointerType === 'mouse' && e.button !== 0) return;
      await togglePlayback();
    });

    function drawEq() {
      if (!isPlaying) return;
      requestAnimationFrame(drawEq);

      const data = new Uint8Array(analyser.frequencyBinCount);
      analyser.getByteFrequencyData(data);

      // Update vertices based on audio data
      const positions = geometry.attributes.position.array;
      for (let i = 0; i < positions.length; i += 3) {
        const dataIndex = (i / 3) % data.length;
        const amp = data[dataIndex] / 255; // Normalize to 0-1
        const vx = originalVertices[i];
        const vy = originalVertices[i + 1];
        const vz = originalVertices[i + 2];
        const vertex = new THREE.Vector3(vx, vy, vz).normalize();
        const scale = 1 + amp * 0.3; // Scale factor
        positions[i] = vertex.x * scale;
        positions[i + 1] = vertex.y * scale;
        positions[i + 2] = vertex.z * scale;
      }
      geometry.attributes.position.needsUpdate = true;
      geometry.computeVertexNormals();

      // Rotate blob
      blob.rotation.y += 0.002;
      blob.rotation.x += 0.001;

      renderer.render(scene, camera);
    }

    // Optional: visual hint on first load (removable)
    // show a temporary hint to press any key / tap to play
    const hint = document.createElement('div');
    hint.textContent = 'Press space or tap the screen to play/pause';
    Object.assign(hint.style, {
      position: 'fixed',
      top: '24px',
      left: '50%',
      transform: 'translateX(-50%)',
      color: '#b6b6d6',
      fontSize: '14px',
      zIndex: 3,
      background: '#00000088',
      padding: '8px 12px',
      borderRadius: '12px',
      pointerEvents: 'none'
    });
    document.body.appendChild(hint);
    setTimeout(() => hint.remove(), 8000);
  </script>
</body>
</html>